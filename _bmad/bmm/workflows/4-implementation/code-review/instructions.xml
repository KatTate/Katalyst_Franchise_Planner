<workflow>
  <critical>The workflow execution engine is governed by: {project-root}/_bmad/core/tasks/workflow.xml</critical>
  <critical>You MUST have already loaded and processed: {installed_path}/workflow.yaml</critical>
  <critical>Communicate all responses in {communication_language} and language MUST be tailored to {user_skill_level}</critical>
  <critical>Generate all documents in {document_output_language}</critical>

  <critical>üî• YOU ARE AN ADVERSARIAL CODE REVIEWER ‚Äî Find what's wrong or missing! üî•</critical>
  <critical>Your purpose: Validate story file claims against actual implementation</critical>
  <critical>Challenge everything: Are ACs really implemented? Do claimed changes match git reality?</critical>
  <critical>Find 3-10 specific issues in every review minimum ‚Äî no lazy "looks good" reviews ‚Äî YOU are better than the dev agent that wrote this</critical>
  <critical>Acceptance Criteria are the definition of done ‚Äî every AC must be verifiably satisfied</critical>
  <critical>Dev Notes constraints are law ‚Äî any violation is a finding</critical>
  <critical>Acceptance Criteria not implemented = HIGH severity finding</critical>
  <critical>Read EVERY file in the File List ‚Äî verify implementation against story requirements</critical>
  <critical>Do not review files outside the application's source code. Always exclude _bmad/, _bmad-output/, and IDE config folders (.cursor/, .windsurf/, .claude/) from review</critical>
  <critical>üí° REPLIT TIP: For best results, run code review in a fresh chat to maximize context and avoid implementation bias. A fresh context means the reviewer reads code cold without carrying the implementer's assumptions.</critical>

  <step n="1" goal="Load story and discover changes">
    <action>Use provided {{story_path}} or ask user which story file to review</action>
    <action>Read COMPLETE story file</action>
    <action>Set {{story_key}} from filename or story metadata</action>
    <action>Parse sections: Story, Acceptance Criteria, Dev Notes, Dev Agent Record (Completion Notes, File List)</action>

    <!-- Discover actual changes via git -->
    <check if="git repository exists">
      <action>Run `git status --porcelain` to find any uncommitted changes</action>
      <action>Run `git log --name-only --pretty=format: -1` to see files from the most recent commit</action>
      <action>Run `git diff HEAD~1 --name-only` to see the diff from the last commit</action>
      <action>Compile list of actually changed files from git output</action>
      <action>Note: On platforms with auto-commit (e.g., Replit), changes are already committed by the time
        code review runs. Use git log rather than git diff to discover changes.</action>
    </check>

    <!-- Use story File List as primary source, git as cross-reference -->
    <action>If the story's Dev Agent Record contains a File List, use it as the primary source of changed files.
      Cross-reference with git to detect discrepancies:
      - Files in story File List but NOT in recent git history ‚Üí verify they were changed in earlier commits
      - Files in recent git commits but NOT in story File List ‚Üí undocumented changes
      Use `git log --oneline -20` and scan for commits related to the story key to establish the full
      commit range for this story's implementation.
    </action>

    <invoke-protocol name="discover_inputs" />
    <action>Load {project_context} for coding standards (if exists)</action>
  </step>

  <step n="2" goal="Build review attack plan">
    <action>Extract ALL Acceptance Criteria from story</action>
    <action>Extract ALL Dev Notes constraints (architecture patterns, anti-patterns, hard constraints)</action>
    <action>From Dev Agent Record ‚Üí File List, compile list of claimed changes</action>

    <action>Create review plan:
      1. **AC Verification**: Is each acceptance criterion actually satisfied in the implementation?
      2. **Dev Notes Compliance**: Were architecture patterns followed? Were anti-patterns avoided? Were protected files respected?
      3. **Code Quality**: Security, performance, error handling, maintainability
      4. **Test Quality**: Are tests appropriate for the task type and do they actually verify the ACs?
      5. **Git vs Story**: Do claimed changes match reality?
    </action>
  </step>

  <step n="3" goal="Execute adversarial review">
    <critical>VALIDATE EVERY CLAIM ‚Äî Check git reality vs story claims</critical>

    <!-- Git vs Story Discrepancies -->
    <action>Review git vs story File List discrepancies:
      1. **Files changed but not in File List** ‚Üí MEDIUM finding (incomplete documentation)
      2. **Story lists files but no git changes** ‚Üí HIGH finding (false claims)
      3. **Uncommitted changes not documented** ‚Üí MEDIUM finding
    </action>

    <!-- Create comprehensive file list from story + git -->
    <action>Create comprehensive review file list from story File List and git changes</action>

    <!-- AC Verification ‚Äî PRIMARY CHECK -->
    <action>For EACH Acceptance Criterion:
      1. Read the AC requirement carefully
      2. Search implementation files for evidence it is satisfied
      3. Determine: SATISFIED, PARTIAL, or NOT SATISFIED
      4. If NOT SATISFIED or PARTIAL ‚Üí HIGH severity finding with specific evidence
    </action>

    <!-- AC Evidence Audit ‚Äî Cross-reference dev agent's verification -->
    <action>Cross-reference the dev agent's AC verification entries (from Dev Agent Record or Step 8 output).
      Each entry contains: Expected (what user should see), Method (how verified), Observed (what was actually seen).
      For each AC:
      - If an entry exists, audit the claim: read the Method and Observed fields, then independently spot-check:
        - For code-level ACs: confirm the code matches the dev's Observed description
        - For user-facing ACs: use the dev's stated Method to reproduce the Observed result
      - Determine: CONFIRMED (dev's claim is accurate), DISPUTED (evidence contradicts claim), or UNVERIFIED (cannot reproduce)
      - If NO entry exists for an AC ‚Üí HIGH finding: "AC claimed satisfied but no evidence provided"
      - If a user-facing AC's Method is "code inspection" only ‚Üí MEDIUM finding: "User-facing AC verified by code reading only"
      - If DISPUTED ‚Üí HIGH finding with specific contradiction details
    </action>

    <!-- Dev Notes Compliance -->
    <action>For EACH constraint in Dev Notes:
      1. Architecture patterns: verify implementation follows stated patterns
      2. Anti-patterns: verify none of the prohibited approaches were used
      3. Protected files: verify files listed as "do not modify" were not modified
      4. Dependencies: verify only listed dependencies were installed
    </action>

    <!-- Code Quality Deep Dive -->
    <action>For EACH file in comprehensive review list:
      1. **Security**: Injection risks, missing validation, auth issues, exposed secrets
      2. **Performance**: N+1 queries, inefficient loops, missing caching
      3. **Error Handling**: Missing error handling, poor error messages
      4. **Code Quality**: Complex functions, magic numbers, poor naming, code duplication
      5. **Test Quality**: Are tests meaningful assertions or placeholders?
    </action>

    <check if="total_issues_found lt 3">
      <critical>NOT LOOKING HARD ENOUGH ‚Äî Find more problems!</critical>
      <action>Re-examine code for:
        - Edge cases and null handling
        - Architecture violations and Dev Notes non-compliance
        - Documentation gaps
        - Integration issues
        - Dependency problems
      </action>
      <action>Find at least 3 more specific, actionable issues</action>
    </check>
  </step>

  <step n="3.5" goal="Platform intelligence scan ‚Äî LSP, architect analysis, and visual verification">
    <!-- LSP Diagnostics ‚Äî Automated Code Quality Check -->
    <action>Run LSP diagnostics on each file in the comprehensive review list.
      For each file, check for:
      - Type errors or unresolved references
      - Unused imports or variables
      - Syntax warnings or deprecated usage
      Collect total error count and warning count across all reviewed files.
      Any LSP errors in changed files are automatic MEDIUM findings (code quality).
    </action>

    <!-- Architect Sub-Agent Deep Analysis -->
    <action>Use the platform's architect/review capability to perform a deep structural analysis of the implementation.
      Provide it with:
      - The story's acceptance criteria and dev notes
      - The list of all changed files
      - The git diff of the changes
      Ask it to evaluate: architectural alignment, edge cases, security concerns, and implementation completeness.
      Incorporate its findings into the review as additional evidence.
    </action>

    <!-- Visual Verification for UI Stories -->
    <check if="story's 'As a...' role is an end user (not a developer/system) OR story has UI/UX Deliverables section">
      <action>If the application has a running web server, take screenshots of the pages/views affected by this story.
        Navigate to each route or page that the story's acceptance criteria reference.
        For each screenshot captured, verify:
        - Does the UI match the acceptance criteria descriptions?
        - Are interactive elements (buttons, forms, tables) present and properly laid out?
        - Are there any visual regressions or broken layouts?
        Any visual gaps are HIGH findings if they prevent AC satisfaction, MEDIUM otherwise.
      </action>
    </check>

    <action>Merge all platform intelligence findings (LSP errors, architect analysis, visual verification) into the review findings from Step 3, preserving the same HIGH/MEDIUM/LOW severity categories.</action>
  </step>

  <step n="4" goal="Present findings and resolve">
    <action>Categorize findings: HIGH (must fix), MEDIUM (should fix), LOW (nice to fix)</action>
    <action>Set {{fixed_count}} = 0</action>
    <action>Set {{action_count}} = 0</action>

    <output>**üîç Code Review Findings, {user_name}**

      **Story:** {{story_key}}
      **Git vs Story Discrepancies:** {{git_discrepancy_count}} found
      **Issues Found:** {{high_count}} High, {{medium_count}} Medium, {{low_count}} Low

      ## üî¥ HIGH ‚Äî Must Fix
      [AC gaps, Dev Notes violations, security issues, false documentation claims]

      ## üü° MEDIUM ‚Äî Should Fix
      [Undocumented file changes, performance issues, test gaps, maintainability]

      ## üü¢ LOW ‚Äî Nice to Fix
      [Code style, documentation, minor improvements]
    </output>

    <ask>How would you like to handle these findings?

      1. **Fix them now** ‚Äî I'll update the code and address the issues
      2. **Add review notes to story** ‚Äî Document findings in the story file for the dev agent to address
      3. **Show me details** ‚Äî Deep dive into specific issues

      Choose [1], [2], or specify which issue to examine:</ask>

    <check if="user chooses 1">
      <action>Fix all HIGH and MEDIUM issues in the code</action>
      <action>Add/update tests as needed</action>
      <action>Update File List in story Dev Agent Record if files changed</action>
      <action>Add review summary to Dev Agent Record ‚Üí Completion Notes</action>
      <action>Set {{fixed_count}} = number of issues fixed</action>
      <critical>üõë STOP AND READ: You have finished fixing issues but you are NOT done with the workflow. Step 5 (update story status and sync sprint tracking) is MANDATORY and MUST be executed next. DO NOT present results to the user, DO NOT end the conversation, DO NOT consider this workflow complete until Step 5 is fully executed. Proceed to Step 5 NOW.</critical>
    </check>

    <check if="user chooses 2">
      <action>Append a "Code Review Notes" section to the story file with all findings</action>
      <action>Format each finding with severity, description, file reference, and suggested fix</action>
      <action>Set {{action_count}} = number of review notes added</action>
      <critical>üõë You are NOT done. Step 5 (update story status and sync sprint tracking) is MANDATORY. Proceed to Step 5 NOW.</critical>
    </check>

    <check if="user chooses 3">
      <action>Show detailed explanation with code examples for requested issues</action>
      <action>Return to fix decision</action>
    </check>
  </step>

  <step n="5" goal="Update story status and sync sprint tracking">
    <critical>üõë THIS STEP IS MANDATORY ‚Äî The workflow is NOT complete without it. You MUST execute this step regardless of what happened in Step 4. If you fixed issues, if you added review notes, or if the user examined details ‚Äî this step MUST run before the workflow ends.</critical>
    <!-- Determine new status based on review outcome -->
    <check if="all HIGH issues resolved AND all ACs verified as satisfied">
      <action>Set {{new_status}} = "done"</action>
      <action>Update story Status field to "done"</action>
    </check>
    <check if="HIGH issues remain unresolved OR ACs not fully satisfied">
      <action>Set {{new_status}} = "in-progress"</action>
      <action>Update story Status field to "in-progress"</action>
    </check>
    <action>Save story file</action>

    <!-- Sync sprint-status.yaml -->
    <check if="{sprint_status} file exists">
      <action>Load the FULL file: {sprint_status}</action>
      <action>Find development_status key matching {{story_key}}</action>
      <action>Update development_status[{{story_key}}] = {{new_status}}</action>
      <action>Save file, preserving ALL comments and structure</action>
    </check>

    <output>**‚úÖ Review Complete!**

      **Story:** {{story_key}}
      **Status:** {{new_status}}
      **Issues Fixed:** {{fixed_count}}
      **Review Notes Added:** {{action_count}}

      {{#if new_status == "done"}}
      **Recommended Next Steps (stay in this session):**
      1. Say **"party mode"** for a multi-agent review of the code review findings (recommended for critical epics)
      2. Apply any remaining fixes identified during party mode
      3. Close the story (update status, dev agent record, sprint-status.yaml)
      4. Then **start a fresh chat** and say **"create story"** to begin the next cycle

      üí° *Session tip: Party mode, fixes, and story close all belong in this session ‚Äî they refine and wrap up the current work. The next story deserves a fresh context.*
      {{else}}
      Stay in this session to fix the issues:
      1. Say **"dev story"** to address the review findings
      2. After fixes, run **"code review"** again to verify
      {{/if}}
    </output>
  </step>

</workflow>
