<workflow>
  <critical>The workflow execution engine is governed by: {project-root}/_bmad/core/tasks/workflow.xml</critical>
  <critical>You MUST have already loaded and processed: {installed_path}/workflow.yaml</critical>
  <critical>Communicate all responses in {communication_language} and language MUST be tailored to {user_skill_level}</critical>
  <critical>Generate all documents in {document_output_language}</critical>
  <critical>User skill level ({user_skill_level}) affects conversation style ONLY, not code quality.</critical>
  <critical>üí° REPLIT TIP: For best results, run this workflow in a fresh chat to maximize available context.</critical>

  <step n="1" goal="Load story file as authoritative context">
    <check if="{{story_path}} is provided">
      <action>Use {{story_path}} directly</action>
      <action>Read COMPLETE story file</action>
      <action>Extract story_key from filename or metadata</action>
      <goto anchor="context_loaded" />
    </check>

    <!-- Sprint-based story discovery -->
    <check if="{{sprint_status}} file exists">
      <critical>MUST read COMPLETE sprint-status.yaml file from start to end to preserve order</critical>
      <action>Load the FULL file: {{sprint_status}}</action>
      <action>Find the FIRST story where status equals "ready-for-dev" or "in-progress"</action>

      <check if="no ready-for-dev or in-progress story found">
        <output>üìã No stories ready for development.

          **Options:**
          1. Say "create story" to create the next story from epics
          2. Specify a particular story file path to develop
        </output>
        <ask>What would you like to do?</ask>
        <action>HALT if user chooses to create story first</action>
      </check>
    </check>

    <!-- Non-sprint story discovery -->
    <check if="{{sprint_status}} file does NOT exist">
      <action>Search {story_dir} for story files with "ready-for-dev" status</action>
      <check if="no ready-for-dev stories found">
        <output>üìã No ready-for-dev stories found.

          **Options:**
          1. Say "create story" to create the next story from epics
          2. Specify which story file to develop
        </output>
        <ask>What would you like to do?</ask>
        <action>HALT if no story to work on</action>
      </check>
    </check>

    <action>Load the discovered story file completely</action>
    <action>Extract story_key from filename</action>

    <anchor id="context_loaded" />

    <action>Parse the story file sections: Story, Acceptance Criteria, Dev Notes, Dev Agent Record</action>
    <action>Treat Dev Notes as HARD CONSTRAINTS ‚Äî these are not suggestions, they are rules</action>
    <action>Treat Acceptance Criteria as the DEFINITION OF DONE ‚Äî every AC must be satisfied</action>
  </step>

  <step n="2" goal="Load project context and mark story in-progress">
    <action>Load {project_context} for coding standards and project-wide patterns (if exists)</action>

    <!-- Check for review continuation -->
    <check if="story status is 'in-progress' or story file contains review feedback from a previous code review">
      <action>Look for any review notes, action items, or feedback sections appended to the story file</action>
      <action>If review feedback exists with unresolved items, prioritize addressing those first</action>
      <output>‚èØÔ∏è **Resuming Implementation:** {{story_key}}
        Will address any pending review feedback before continuing.
      </output>
    </check>

    <check if="story status is 'ready-for-dev' and no prior review feedback exists">
      <output>üöÄ **Starting Implementation:** {{story_key}}</output>
    </check>

    <!-- Update sprint status -->
    <check if="{{sprint_status}} file exists">
      <action>Update story status to "in-progress" if currently "ready-for-dev"</action>
    </check>

    <action>Update story file Status to "in-progress"</action>
  </step>

  <step n="3" goal="Plan and implement">
    <critical>Create your own implementation plan from the acceptance criteria and dev notes.
      Use the platform's native task management to track your work. Do NOT write a task list
      into the story file.</critical>

    <critical>Dev Notes constraints are LAW:
      - "Anti-Patterns and Hard Constraints" ‚Äî violations are bugs
      - "Architecture Patterns to Follow" ‚Äî deviations require justification
      - "File Change Summary" ‚Äî directional guidance, not rigid prescription
      - "Dependencies" ‚Äî install what's listed, do not reinstall what's already present
    </critical>

    <critical>USER-FACING STORY CHECK: Before planning, determine if this story is user-facing.
      If the story's "As a..." role is an end user (not a developer), the implementation plan
      MUST include UI work ‚Äî pages, forms, tables, components. An end-user story implemented
      as API-only (without a usable interface) is INCOMPLETE regardless of whether all API
      acceptance criteria pass. If the story's Dev Notes include a "UI/UX Deliverables" section,
      those deliverables are REQUIRED outputs.</critical>

    <action>Create an implementation plan based on acceptance criteria and dev notes</action>
    <action>Implement the plan, following all Dev Notes constraints</action>

    <action>Test appropriately for the task type:
      - Schema, config, and infrastructure tasks: verify by running them
      - Business logic and API endpoints: write tests
      - UI components: verify visually and functionally
      - User-facing stories: MUST verify that a real user can perform the actions described
        in the acceptance criteria through the UI ‚Äî not just via API calls or curl commands
      - The agent decides the testing approach based on what makes sense
    </action>

    <action>Document the testing approach in the task list or notes:
      - What type of testing was performed (unit tests, visual verification, manual run, etc.)
      - Which test files were created or modified
      - Which ACs each test covers
      This documentation enables the Code Review workflow to efficiently verify test coverage
      without re-discovering the testing strategy.
    </action>

    <action if="new dependencies required beyond what's listed in Dev Notes">ASK user for approval before adding</action>
    <action if="implementation conflicts with Dev Notes constraints">HALT and explain the conflict</action>
    <action if="acceptance criteria are ambiguous or contradictory">ASK user to clarify</action>
  </step>

  <step n="4" goal="Verify against acceptance criteria">
    <critical>Every acceptance criterion must be verified. This is the definition of done.</critical>

    <action>Walk through each acceptance criterion and verify it is satisfied</action>

    <critical>USER-FACING DELIVERY CHECK: If the story's "As a..." role is an end user,
      verify that every AC can be satisfied by a user interacting with the UI ‚Äî not just by
      calling the API directly. If ACs describe user actions (filling forms, clicking buttons,
      viewing tables) but no UI exists for those actions, the story is NOT done. Build the UI
      before marking complete.</critical>

    <action>Run all existing tests to ensure no regressions</action>
    <action>Run any new tests to verify implementation correctness</action>

    <check if="any acceptance criterion is NOT satisfied">
      <action>Fix the implementation until all ACs pass</action>
      <action>If unable to satisfy an AC, HALT and explain what's blocking</action>
    </check>

    <check if="regression tests fail">
      <action>Fix regressions before proceeding ‚Äî do not leave broken tests</action>
    </check>
  </step>

  <step n="4.5" goal="Post-implementation platform verification">
    <!-- LSP Diagnostics ‚Äî Verify No New Errors -->
    <action>Run LSP diagnostics on all files that were created or modified during this story.
      Check for:
      - Type errors or unresolved references introduced by the implementation
      - Unused imports or variables
      - Syntax warnings or deprecated usage
      If LSP reports errors in files changed during this story, fix them before proceeding.
      Warnings should be noted but do not block completion.
    </action>

    <!-- Git Status Verification -->
    <action>Run `git status --porcelain` to verify all implementation changes are tracked.
      Check that:
      - No untracked files that should be committed are missing
      - No unexpected files were modified outside the story's scope
      - The working directory state is clean and documented
    </action>

    <!-- Visual Verification for UI Stories -->
    <check if="story's 'As a...' role is an end user OR story has UI/UX Deliverables section">
      <action>If the application has a running web server, take screenshots of the pages/views that were built or modified by this story.
        Navigate to the routes referenced in the acceptance criteria.
        Verify that:
        - The UI elements described in the ACs are visible and properly rendered
        - No visual regressions or broken layouts are apparent
        - The page looks like what a user would expect from the story description
        If screenshots reveal missing or broken UI elements, fix them before proceeding.
      </action>
    </check>
  </step>

  <step n="5" goal="Update story file and sprint status">
    <action>Update story file Status to "review"</action>

    <action>Update Dev Agent Record:
      - Agent Model Used
      - Completion Notes: brief summary of what was implemented and key decisions
      - File List: all files created, modified, or deleted (paths relative to repo root)
      - Testing Summary: test approach used, test files created/modified, ACs covered by tests, all tests passing (yes/no)
      - LSP Status: clean / [N] errors found and fixed / [N] warnings remaining
      - Visual Verification: screenshots taken and verified (if user-facing story) / N/A
    </action>

    <!-- Update sprint status -->
    <check if="{{sprint_status}} file exists">
      <action>Load the FULL file: {{sprint_status}}</action>
      <action>Update development_status[{{story_key}}] = "review"</action>
      <action>Save file, preserving ALL comments and structure</action>
    </check>

    <action>Use the platform's architect/review tool to review the implementation for quality</action>
  </step>

  <step n="6" goal="Communicate completion">
    <action>Summarize what was implemented: story key, key changes, files modified</action>

    <action>Based on {user_skill_level}, offer to explain:
      - What was implemented and how it works
      - Why certain technical decisions were made
      - How to test or verify the changes
    </action>

    <output>
      **Recommended Next Steps:**
      1. **Start a fresh chat** and say **"code review"** ‚Äî a fresh perspective catches what the implementer missed
      2. In that review session: run **"party mode"** on the findings, apply fixes, and close the story
      3. Then **start a fresh chat** and say **"create story"** to begin the next cycle

      üí° *Fresh chat tip: Code review is most effective when the reviewer reads the code cold, without the implementation context biasing its perspective.*
    </output>

    <check if="{{sprint_status}} file exists">
      <action>Mention current sprint progress</action>
    </check>
  </step>

</workflow>
